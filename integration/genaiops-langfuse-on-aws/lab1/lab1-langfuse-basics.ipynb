{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Langfuse Tracing\n",
    "\n",
    "In this lab, we will learn how to use Langfuse tracing to log and analyze the execution of your LLM applications. The Langfuse supports self-hosted on AWS (this lab) and there is a [cloud version](https://cloud.langfuse.com/) available. [Tracing](https://langfuse.com/docs/tracing) in Langfuse is a way to log and analyze the execution of your LLM applications and following reference provides a detailed overview of the data model used. It is inspired by OpenTelemetry.\n",
    "\n",
    "\n",
    "## [Traces and Observations](https://langfuse.com/docs/tracing-data-model)\n",
    "A trace typically represents a single request or operation. It contains the overall input and output of the function, as well as metadata about the request, such as the user, the session, and tags. Usually, a trace corresponds to a single api call of an application.\n",
    "\n",
    "Each trace can contain multiple observations to log the individual steps of the execution.\n",
    "\n",
    "- Observations are of different types:\n",
    "    - Events are the basic building blocks. They are used to track discrete events in a trace.\n",
    "    - Spans represent durations of units of work in a trace.\n",
    "    - Generations are spans used to log generations of AI models. They contain additional attributes about the model, the prompt, and the completion. For generations, [token usage and costs](https://langfuse.com/docs/model-usage-and-cost) are automatically calculated.\n",
    "- Observations can be nested.\n",
    "\n",
    "![Trace and Observations](./images/trace-observation.png)\n",
    "![Trace and Observations UI](./images/trace-observation-ui.png)\n",
    "\n",
    "## [Sessions](https://langfuse.com/docs/tracing-data-model)\n",
    "Optionally, traces can be grouped into sessions. Sessions are used to group traces that are part of the same user interaction. A common example is a thread in a chat interface.\n",
    "Please refer to the [Sessions documentation](https://langfuse.com/docs/sessions) to add sessions to your traces.\n",
    "\n",
    "![Trace and Sessions](./images/trace-sessions.png)\n",
    "![Trace and Sessions UI](./images/trace-sessions-ui.png)\n",
    "\n",
    "\n",
    "## [Scores](https://langfuse.com/docs/tracing-data-model)\n",
    "\n",
    "Traces and observations can be evaluated using [scores](https://langfuse.com/docs/scores/overview). Scores are flexible objects that store evaluation metrics and can be:\n",
    "\n",
    "- Numeric, categorical, or boolean values\n",
    "- Associated with a trace (required)\n",
    "- Linked to a specific observation (optional)\n",
    "- Annotated with comments for additional context\n",
    "- Validated against a score configuration schema (optional)\n",
    "\n",
    "![Trace and Scores](./images/trace-scores.png)\n",
    "\n",
    "Please refer to the [scores documentation](https://langfuse.com/docs/scores/overview) to get started. For more details on score types and attributes, refer to the [score data model documentation](https://langfuse.com/docs/scores/data-model).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Scores\n",
    "\n",
    "Traces and observations can be evaluated using [scores](https://langfuse.com/docs/scores/overview). Scores are flexible objects that store evaluation metrics and can be:\n",
    "\n",
    "- Numeric, categorical, or boolean values\n",
    "- Associated with a trace (required)\n",
    "- Linked to a specific observation (optional)\n",
    "- Annotated with comments for additional context\n",
    "- Validated against a score configuration schema (optional)\n",
    "\n",
    "![Trace and Scores](./images/trace-scores.png)\n",
    "\n",
    "[Source](https://langfuse.com/docs/scores/overview)\n",
    "\n",
    "Please refer to the [scores documentation](https://langfuse.com/docs/scores/overview) to get started. For more details on score types and attributes, refer to the [score data model documentation](https://langfuse.com/docs/scores/data-model).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites\n",
    "\n",
    "> If you haven't selected the kernel, please click on the \"Select Kernel\" button at the upper right corner, select Python Environments and choose \".venv (Python 3.9.20) .venv/bin/python Recommended\".\n",
    "\n",
    "> To execute each notebook cell, press Shift + Enter.\n",
    "\n",
    "> ℹ️ You can **skip these prerequisite steps** if you're in an instructor-led workshop using temporary accounts provided by AWS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Environment Variables\n",
    "\n",
    "We will use the langfuse and boto3:\n",
    "- The Langfuse Python SDK along with the self-hosting deployment to debug and improve LLM applications by tracing model invocations, managing prompts / models configurations and running evaluations.\n",
    "- The boto3 SDK to interact with models on Amazon Bedrock or Amazon SageMaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command to install the required Python SDKs.\n",
    "> Please feel free to skip the installation if you are using a provided AWS account in a AWS organised event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line to install dependencies if you are not using AWS workshop environment\n",
    "# %pip install -q langfuse boto3  --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you have completed the prerequisites to setup the Langfuse project and API keys in the .env file to connect to self-hosted or cloud Langfuse environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you already define the environment variables in the .env of the vscode server, please skip the following cell\n",
    "# Define the environment variables for langfuse\n",
    "# You can find those values when you create the API key in Langfuse\n",
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"xxxx\" # Your Langfuse project secret key\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"xxxx\" # Your Langfuse project public key\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"xxx\" # Langfuse domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Langfuse documentation](https://langfuse.com/docs/get-started) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and Authentication Check\n",
    "Run the following cells to initialize common libraries and clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary packages\n",
    "import sys\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import boto3\n",
    "from langfuse import Langfuse\n",
    "from langfuse.decorators import langfuse_context, observe\n",
    "from langfuse.model import PromptClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create bedrock client and bedrock runtime client and please make sure the region is us-west-2 for this lab. The expected result is to see the following output:\n",
    "\n",
    "```\n",
    "Found Nova model: US Nova Pro - us.amazon.nova-pro-v1:0\n",
    "Found Nova model: US Nova Lite - us.amazon.nova-lite-v1:0\n",
    "Found Nova model: US Nova Micro - us.amazon.nova-micro-v1:0\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "> As Nova models in us-west-2 can only be called via Cross-Region Inference (CRIS), the model_id has \"us.\" prefix to indicate this is a CRIS call. This can add latency to the model call.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Nova model: US Nova Pro - us.amazon.nova-pro-v1:0\n",
      "Found Nova model: US Nova Lite - us.amazon.nova-lite-v1:0\n",
      "Found Nova model: US Nova Micro - us.amazon.nova-micro-v1:0\n"
     ]
    }
   ],
   "source": [
    "# used to access Bedrock configuration\n",
    "# region has to be in us-west-2 for this lab\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-west-2\")\n",
    "\n",
    "# Check if Nova models are available in this region\n",
    "models = bedrock.list_inference_profiles()\n",
    "nova_found = False\n",
    "for model in models[\"inferenceProfileSummaries\"]:\n",
    "    if (\n",
    "        \"Nova Pro\" in model[\"inferenceProfileName\"]\n",
    "        or \"Nova Lite\" in model[\"inferenceProfileName\"]\n",
    "        or \"Nova Micro\" in model[\"inferenceProfileName\"]\n",
    "    ):\n",
    "        print(\n",
    "            f\"Found Nova model: {model['inferenceProfileName']} - {model['inferenceProfileId']}\"\n",
    "        )\n",
    "        nova_found = True\n",
    "if not nova_found:\n",
    "    raise ValueError(\n",
    "        \"No Nova models found in available models. Please ensure you have access to Nova models.\"\n",
    "    )\n",
    "#  Coverage, log level, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the Langfuse client and check credentials are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "# langfuse client\n",
    "langfuse = Langfuse()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse has been set up correctly\")\n",
    "    print(f\"You can access your Langfuse instance at: {os.environ['LANGFUSE_HOST']}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Credentials not found or invalid. Check your Langfuse API key and host in the .env file.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langfuse Wrappers for Bedrock Converse API \n",
    "You can use the Amazon Bedrock Converse API to create conversational applications that send and receive messages to and from an Amazon Bedrock model. For example, you can create a chat bot that maintains a conversation over many turns and uses a persona or tone customization that is unique to your needs, such as a helpful technical support assistant.\n",
    "\n",
    "To use the Converse API, you use the Converse or ConverseStream (for streaming responses) operations to send messages to a model. It is possible to use the existing base inference operations (InvokeModel or InvokeModelWithResponseStream) for conversation applications. However, we recommend using the Converse API as it provides consistent API, that works with all Amazon Bedrock models that support messages. This means you can write code once and use it with different models. Should a model have unique inference parameters, the Converse API also allows you to pass those unique parameters in a model specific structure.\n",
    "\n",
    "For more details, please refer to the [Carry out a conversation with the Converse API operations](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))  # Add parent directory to path\n",
    "from config import GUARDRAIL_CONFIG, MODEL_CONFIG\n",
    "from utils import converse, converse_tool_use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Examples\n",
    "\n",
    "#### Define a helper function to call the  Converse API wrapper\n",
    "\n",
    "> Please make sure your have setup the Nova custom model pricing per mentioned in  [Langfuse Setup](https://catalog.workshops.aws/genaiops-langfuse/en-US/00-introduction/langfuse-setup) under Introduction section of the workshop studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Simple Chat\")\n",
    "def simple_chat(\n",
    "    model_config: dict,\n",
    "    messages: list,\n",
    "    prompt: PromptClient = None,\n",
    "    use_guardrails: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Executes a simple chat interaction using the specified model configuration.\n",
    "\n",
    "    Args:\n",
    "        model_config (dict): Configuration parameters for the chat model.\n",
    "        messages (list): A list of message dictionaries to be processed.\n",
    "        prompt (PromptClient, optional): Optional prompt client for advanced handling.\n",
    "        use_guardrails (bool, optional): When True, applies additional guardrail configurations.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the 'converse' function call.\n",
    "    \"\"\"\n",
    "    config = model_config.copy()\n",
    "    if use_guardrails:\n",
    "        config[\"guardrailConfig\"] = GUARDRAIL_CONFIG\n",
    "    return converse(messages=messages, prompt=prompt, **config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 1\n",
    "let's start with a single turn chat use case and use Nova Pro as the default model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'nova_pro', 'response': 'Certainly! Checking in a guest at a luxury resort involves several steps to ensure a seamless, personalized, and memorable experience. Here’s a detailed, step-by-step process:\\n\\n### Pre-Arrival\\n1. **Reservation Confirmation**\\n   - The guest’s reservation is confirmed via email or phone.\\n   - Special requests (dietary preferences, room preferences, etc.) are noted.\\n\\n2. **Pre-Arrival Communication**\\n   - A welcome email is sent with resort information, directions, and any special offers.\\n   - The guest may receive a call to confirm their arrival time and any specific needs.\\n\\n### Arrival\\n3. **Welcome at the Entrance**\\n   - A staff member greets the guest by name as they arrive, offering assistance with luggage.\\n   - Valet parking or a bellhop service may be provided.\\n\\n### Check-In Process\\n4. **Front Desk Greeting**\\n   - The guest is warmly welcomed at the front desk.\\n   - The front desk agent addresses the guest by name and confirms their reservation.\\n\\n5. **Document Verification**\\n   - The guest presents identification (passport, driver’s license) and a credit card for incidentals.\\n   - The front desk agent verifies the information against the reservation details.\\n\\n6. **Room Assignment**\\n   - The agent informs the guest about their room number and any special features of their room (e.g., ocean view, private balcony).\\n   - If the guest has a preference or made a special request, the agent confirms it has been accommodated.\\n\\n7. **Overview of Resort Amenities**\\n   - The agent provides an overview of the resort’s amenities (spa, restaurants, activities, etc.).\\n   - Information about daily activities or events is shared.\\n\\n8. **Electronic Key and Instructions**\\n   - The guest receives their electronic room key.\\n   - Brief instructions on resort policies (check-out time, Wi-Fi access, etc.) are provided.\\n\\n9. **Special Touches**\\n   - The resort may offer a complimentary drink or a cool towel to the guest.\\n   - A personalized welcome note or gift may be included.\\n\\n### Post Check-In\\n10. **Escort to Room (Optional)**\\n    - A staff member may escort the guest to their room, especially if it’s their first visit or if they’ve requested it.\\n    - The staff member ensures the guest is comfortable and that everything is to their satisfaction.\\n\\n11. **Follow-Up**\\n    - The front desk may check in with the guest later to ensure they are settling in well and if they need any assistance.\\n\\n### Throughout the Stay\\n12. **Ongoing Communication**\\n    - The resort staff may periodically check in with the guest to ensure their stay is enjoyable and to address any needs or concerns.\\n    - Daily turn-down service may be provided in the evening.\\n\\n### Check-Out\\n13. **Pre-Check-Out Communication**\\n    - A day before check-out, the resort may contact the guest to confirm their departure time and offer assistance with arrangements (transportation, late check-out, etc.).\\n\\n14. **Final Billing**\\n    - The guest’s final bill is prepared, including any charges for minibar, spa services, or other amenities.\\n    - The bill is reviewed with the guest, and payment is processed.\\n\\n15. **Feedback Request**\\n    - The guest may be asked to provide feedback on their stay, either through a survey or a direct conversation.\\n\\n16. **Goodbye and Future Stay Invitation**\\n    - The guest is thanked for their stay and invited to return in the future.\\n    - A staff member may assist with luggage and transportation arrangements.\\n\\nThis meticulous process ensures that guests at a luxury resort feel valued, comfortable, and well-cared for throughout their stay.', 'statusCode': 200}\n"
     ]
    }
   ],
   "source": [
    "# Decorator to observe and track this function execution in Langfuse\n",
    "@observe(name=\"Single Turn Example\")\n",
    "def chat_single_model(\n",
    "    messages: list, model_type: str = \"nova_pro\", use_guardrails: bool = False\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute a single turn chat interaction using one specified Nova model.\n",
    "\n",
    "    Args:\n",
    "        messages (list): The user's input query\n",
    "        model_type (str): The Nova model to use (nova_pro, nova_lite, or nova_micro)\n",
    "        use_guardrails (bool): Whether to apply guardrails to the model invocation\n",
    "\n",
    "    Returns:\n",
    "        dict: Response containing model output and status code\n",
    "    \"\"\"\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        tags=[\"lab1\", \"single-turn\"],\n",
    "    )\n",
    "\n",
    "    response = simple_chat(\n",
    "        model_config=MODEL_CONFIG[model_type],\n",
    "        messages=messages,\n",
    "        use_guardrails=use_guardrails,\n",
    "    )\n",
    "\n",
    "    return {\"model\": model_type, \"response\": response, \"statusCode\": 200}\n",
    "\n",
    "\n",
    "# Make a sample request to test the chat API\n",
    "# Ask about luxury resort check-in process\n",
    "print(\n",
    "    chat_single_model(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain the process of checking in a guest at a luxury resort, think step by step.\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Force immediate sending of the trace data to Langfuse\n",
    "# Rather than waiting for automatic flush\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Langfuse dashboard, you can find the summary of the traces, model costs and model usage.:\n",
      "https://us.cloud.langfuse.com\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"In Langfuse dashboard, you can find the summary of the traces, model costs and model usage.:\\n{os.environ['LANGFUSE_HOST']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Langfuse Dashboard](./images/langfuse-dashboard-use-case-1.png)\n",
    "\n",
    "\n",
    "The detailed traced can be found in the **Traces** section and you can click on the trace to see the detailed trace. And there are some key insights in this trace.\n",
    "\n",
    "- input token is 12 and output token is 662, in total there are 675 tokens used\n",
    "\n",
    "- The model used is us.amazon.nova-pro-v1:0\n",
    "\n",
    "- Model parameters are shown such as temperature, max_tokens, etc.\n",
    "\n",
    "- Most importantly, the total cost of this invovation costs $0.002129 \n",
    "\n",
    "![Langfuse Dashboard](./images/langfuse-trace-use-case-1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 2\n",
    "This use case demonstrates running a single trace within one session, where we'll execute three distinct observations using different Nova model variants for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'responses': {'nova_pro': 'Certainly! Checking in a guest at a luxury resort involves several steps to ensure a seamless and memorable experience. Here’s a detailed, step-by-step process:\\n\\n### Pre-Arrival\\n1. **Reservation Confirmation**:\\n   - The guest’s reservation is confirmed via email or phone.\\n   - Special requests (dietary preferences, room preferences, etc.) are noted.\\n\\n2. **Pre-Registration**:\\n   - Guests may be sent a link to complete pre-registration forms online.\\n   - This includes personal information, preferences, and any special requests.\\n\\n### Arrival\\n3. **Welcome at the Entrance**:\\n   - A greeter welcomes the guest by name as they arrive.\\n   - Bellhops assist with luggage and provide directions to the check-in area.\\n\\n### Check-In Process\\n4. **Greeting at the Front Desk**:\\n   - The front desk staff greets the guest warmly by name.\\n   - A brief inquiry about the guest’s journey may be made to show care and interest.\\n\\n5. **Verification of Identity**:\\n   - The guest presents identification (passport, driver’s license) and the reservation confirmation.\\n   - The front desk staff verifies the details against the reservation system.\\n\\n6. **Review of Reservation Details**:\\n   - The staff reviews the reservation details with the guest, including room type, rate, and included amenities.\\n   - Any special requests or preferences are confirmed.\\n\\n7. **Digital Check-In (Optional)**:\\n   - Some resorts may offer digital check-in via a tablet or mobile app for a faster process.\\n\\n8. **Room Assignment**:\\n   - The guest is informed of their room number and any special features of the room.\\n   - A resort map may be provided, highlighting key amenities and services.\\n\\n9. **Explanation of Resort Amenities**:\\n   - The front desk staff briefly explains the resort’s amenities, such as dining options, spa services, activities, and any exclusive experiences.\\n   - Information about resort hours, events, and special offers may be shared.\\n\\n10. **Payment and Deposit**:\\n    - The guest’s payment method is collected, and any required deposit is explained.\\n    - For luxury resorts, this may include details about incidental charges.\\n\\n### Post Check-In\\n11. **Electronic Room Key**:\\n    - The guest receives an electronic room key or key card.\\n    - Instructions on how to use the key are provided.\\n\\n12. **Escort to the Room (Optional)**:\\n    - A staff member may escort the guest to their room, especially if it’s their first visit or if they have specific requests.\\n    - The bellhop may deliver luggage to the room.\\n\\n13. **Welcome Amenities**:\\n    - Upon entering the room, the guest finds welcome amenities such as fruits, chocolates, a welcome letter, or a small gift.\\n\\n### Ongoing Service\\n14. **Follow-Up**:\\n    - Front desk staff may check in with the guest later to ensure everything is to their satisfaction.\\n    - Concierge services are available for any additional requests or assistance.\\n\\n### Departure\\n15. **Check-Out Process**:\\n    - Guests can check out via the front desk or through a self-service kiosk if available.\\n    - The guest’s account is reviewed for any charges or credits.\\n    - Feedback may be solicited to improve future stays.\\n\\n16. **Goodbye and Future Reservations**:\\n    - The staff thanks the guest for their stay and inquires about future visits.\\n    - Information about loyalty programs or special offers for return visits may be provided.\\n\\nThis meticulous process ensures that guests feel valued, comfortable, and well-informed throughout their stay at a luxury resort.', 'nova_lite': 'Certainly! Checking in a guest at a luxury resort involves a series of meticulous steps designed to ensure a seamless, personalized, and memorable experience. Here’s a step-by-step breakdown of the process:\\n\\n### Pre-Arrival Preparation\\n1. **Reservation Confirmation:**\\n   - **Booking Confirmation:** The guest receives a confirmation email with all the details of their reservation, including check-in time, room type, and any special requests.\\n   - **Pre-Arrival Communication:** The resort may send a welcome email or a series of communications to gather information about the guest’s preferences, dietary restrictions, and any special needs.\\n\\n2. **VIP Guest Identification:**\\n   - **VIP Status Verification:** If the guest is a frequent visitor or a VIP, their profile is reviewed to prepare any special amenities or upgrades.\\n   - **Personalized Welcome:** A personalized welcome message or gift may be arranged.\\n\\n### Arrival and Initial Greeting\\n3. **Arrival and Reception:**\\n   - **Welcome Desk:** The guest is greeted by a friendly and professional concierge or front desk staff at the reception area.\\n   - **Identification and Documentation:** The guest is asked to present their ID and any reservation confirmation documents.\\n\\n4. **Warm Welcome:**\\n   - **Personalized Greeting:** The guest is welcomed by name, and any special requests or preferences are acknowledged.\\n   - **Luggage Assistance:** Bell staff may assist with luggage.\\n\\n### Check-In Process\\n5. **Room Allocation:**\\n   - **Room Selection:** Based on the reservation and guest preferences, the appropriate room is selected. For VIPs, an upgrade may be offered.\\n   - **Room Preparation:** The room is prepared and any pre-requested amenities (e.g., special bedding, turn-down service) are arranged.\\n\\n6. **Guest Registration:**\\n   - **Digital Check-In:** The guest completes any necessary digital check-in forms if not already done online.\\n   - **Personal Information:** The guest’s personal information, including contact details and emergency contacts, is recorded.\\n\\n7. **Special Requests and Preferences:**\\n   - **Special Requests:** Any special requests made during the reservation process are reviewed and confirmed.\\n   - **Allergies and Preferences:** Dietary preferences, room preferences, and any other special needs are noted.\\n\\n### Providing Information and Amenities\\n8. **Resort Information:**\\n   - **Resort Amenities:** The guest is briefed on the resort’s amenities, including dining options, spa services, recreational activities, and local attractions.\\n   - **Safety and Policies:** Important information regarding safety protocols, resort policies, and emergency procedures is shared.\\n\\n9. **Room Tour:**\\n   - **Room Presentation:** The guest is escorted to their room, and the room features and amenities are explained.\\n   - **Technology Briefing:** Any technology in the room, such as smart controls, entertainment systems, and connectivity options, is demonstrated.\\n\\n### Enhancing the Experience\\n10. **Personalized Touches:**\\n    - **Welcome Amenities:** A welcome amenity, such as a welcome drink, fruit platter, or a handwritten note, is provided.\\n    - **Special Surprises:** For VIP guests, a special surprise or upgrade may be presented.\\n\\n### Finalizing the Check-In\\n11. **Payment and Billing:**\\n    - **Payment Options:** The guest is informed about the payment options and any resort credits or packages they may have.\\n    - **Billing Information:** Billing details are confirmed, and any questions regarding the bill are addressed.\\n\\n12. **Confirmation and Follow-Up:**\\n    - **Confirmation:** The guest is given a confirmation of their check-in details and any next steps.\\n    - **Feedback Request:** The guest is asked if they need any further assistance and if there’s anyone from the team they’d like to speak with for any additional requests.\\n\\n### Continuous Service\\n13. **Ongoing Support:**\\n    - **Availability:** The guest is informed about the availability of 24/7 concierge service for any needs or requests during their stay.\\n    - **Check-Out Preparation:** Even during the check-in, the team starts preparing for the guest’s check-out, ensuring a smooth transition.\\n\\nBy following these steps, a luxury resort ensures that each guest feels valued, well-cared for, and excited about their stay from the moment they arrive.', 'nova_micro': 'Checking in a guest at a luxury resort is a meticulous process designed to ensure a seamless and memorable experience from the moment they arrive. Here’s a step-by-step breakdown:\\n\\n### 1. **Pre-Arrival Preparation**\\n   - **Reservation Confirmation:** Verify the guest’s reservation details, including special requests (e.g., dietary restrictions, room preferences).\\n   - **Pre-Arrival Communication:** Send a welcome email with check-in instructions, amenities information, and resort details.\\n   - **Room Preparation:** Ensure the room is cleaned, stocked, and personalized according to the guest’s preferences.\\n\\n### 2. **Guest Arrival**\\n   - **Arrival Greeting:** Have a concierge or front desk staff member ready to greet the guest as they arrive.\\n   - **Security Check:** Ensure all guests provide necessary identification and security checks are completed.\\n\\n### 3. **Check-In Process**\\n   - **Welcome:** Greet the guest warmly and offer assistance.\\n   - **Document Verification:** Verify the guest’s identification and check their reservation.\\n   - **Special Requests:** Review any special requests or preferences noted in the reservation system.\\n   - **Payment Processing:** Handle payment for any outstanding balances, deposits, or resort fees. Offer various payment options (credit card, mobile payment, etc.).\\n   - **Membership/Loyalty Program:** If applicable, enroll the guest in the resort’s loyalty program and explain the benefits.\\n\\n### 4. **Room Assignment**\\n   - **Room Presentation:** Escort the guest to the room and provide a brief overview of the room amenities and resort facilities.\\n   - **Room Tour:** Offer a tour of the room, highlighting features such as the bathroom, minibar, technology, and any special services available.\\n   - **Personal Touch:** Present any personalized items (e.g., welcome note, custom amenities).\\n\\n### 5. **Guest Information**\\n   - **Amenity Kit:** Provide a detailed amenity kit with information on resort services, dining options, spa services, and activities.\\n   - **Map and Guide:** Offer a map of the resort and a guide to help the guest navigate the facilities.\\n\\n### 6. **Additional Services**\\n   - **Transportation:** Arrange for airport transfers or other transportation services if requested.\\n   - **Valet Service:** Offer valet parking services if available.\\n   - **Baggage Assistance:** Provide assistance with luggage and arrange for bellhop services if needed.\\n\\n### 7. **Final Touches**\\n   - **Feedback Opportunity:** Ask if the guest needs anything else and provide an opportunity to leave initial feedback.\\n   - **Contact Information:** Provide contact information for front desk, concierge, and other services in case the guest needs assistance during their stay.\\n   - **Welcome Drink:** Offer a complimentary welcome drink or snack in the lobby or room.\\n\\n### 8. **Follow-Up**\\n   - **Check-In Satisfaction:** After a few hours, a staff member may check in to ensure the guest is comfortable and everything is to their satisfaction.\\n   - **Room Service:** Introduce room service options and procedures.\\n\\nBy following these steps, a luxury resort ensures that each guest feels valued, comfortable, and well-cared for from the moment they arrive until they depart.'}, 'statusCode': 200}\n"
     ]
    }
   ],
   "source": [
    "@observe(name=\"Multi-Turn Example\")\n",
    "def chat_compare_models(\n",
    "    messages: list,\n",
    "    model_types: list = [\"nova_pro\", \"nova_lite\", \"nova_micro\"],\n",
    "    use_guardrails: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Execute the same query across all Nova models for comparison.\n",
    "\n",
    "    Args:\n",
    "        messages (list): The user's input query\n",
    "        model_types (list): The Nova models to use (nova_pro, nova_lite, or nova_micro)\n",
    "        use_guardrails (bool): Whether to apply guardrails to the model invocation\n",
    "    Returns:\n",
    "        dict: Responses from all models and status code\n",
    "    \"\"\"\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"model-comparison\",\n",
    "        tags=[\"lab1\", \"model-comparison\"],\n",
    "    )\n",
    "\n",
    "    responses = {}\n",
    "    for model_type in model_types:\n",
    "        responses[model_type] = simple_chat(\n",
    "            model_config=MODEL_CONFIG[model_type],\n",
    "            messages=messages,\n",
    "            use_guardrails=use_guardrails,\n",
    "        )\n",
    "\n",
    "    return {\"responses\": responses, \"statusCode\": 200}\n",
    "\n",
    "\n",
    "# user request\n",
    "print(\n",
    "    chat_compare_models(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain the process of checking in a guest at a luxury resort, think step by step.\",\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can combine multiple observations into one trace and see the cost and usage of each observation. Nova micro has the lowest cost and fastest response time.\n",
    "\n",
    "![langfuse-traces-use-case-2](./images/langfuse-trace-use-case-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 3\n",
    "In this case, let's simulate a RAG use case with a dummy retrieval function called retrieve_context, it is a dummy function that returns a static context.\n",
    "We will simply reuse the simple_chat function to chat with the model by passing the context from the retrieval function as part of the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = \"\"\"1st January 2025\n",
    "Sydney: 24 degrees celcius.\n",
    "New York: 13 degrees celcius.\n",
    "Tokyo: 11 degrees celcius.\"\"\"\n",
    "\n",
    "\n",
    "@observe(name=\"Dummy Retrieval\")\n",
    "def retrieve_context(query: str) -> str:\n",
    "    \"\"\"Retrieves static context for the given query.\"\"\"\n",
    "    return CONTEXT\n",
    "\n",
    "\n",
    "@observe(name=\"RAG Example\")\n",
    "def rag_api(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Performs a Retrieval-Augmented Generation (RAG) query using a static context.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "\n",
    "    Returns:\n",
    "        dict: The response from the model and a status code.\n",
    "    \"\"\"\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"rag-session\",\n",
    "        tags=[\"lab1\", \"rag-example\"],\n",
    "    )\n",
    "\n",
    "    context = retrieve_context(query)\n",
    "    messages = [\n",
    "        {\n",
    "            \"content\": f\"Context: {context}\\nBased on the context above, answer the following question:\",\n",
    "            \"role\": \"system\",\n",
    "        },\n",
    "        {\"content\": query, \"role\": \"user\"},\n",
    "    ]\n",
    "    response = simple_chat(model_config=MODEL_CONFIG[\"nova_pro\"], messages=messages)\n",
    "\n",
    "    return {\"response\": response, \"statusCode\": 200}\n",
    "\n",
    "\n",
    "# User request\n",
    "print(rag_api(\"how you like the weather in Sydney? any comments?\"))\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the trace, you can see the retrieval function is called and the context is passed to the model as part of the system prompt. The fine model invocation takes both system prompt and user prompt and return the response.\n",
    "\n",
    "![langfuse-traces-use-case-3](./images/langfuse-trace-use-case-3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Case 4\n",
    "\n",
    "Multi-Modal Capabilities with Image Support\n",
    "\n",
    "Modern AI systems are increasingly adopting multi-modal capabilities, allowing them to process and understand different types of data inputs, including text, images, and audio. In this example, we demonstrate how Langfuse supports tracing for image-based inputs, which is particularly valuable for:\n",
    "\n",
    "1. **Image Analysis**: Interpreting and describing visual content\n",
    "2. **Visual Question Answering**: Answering questions based on image context\n",
    "3. **Document Processing**: Extracting information from scanned documents or images\n",
    "4. **Content Moderation**: Identifying inappropriate or sensitive visual content\n",
    "\n",
    "The implementation uses a structured message format where the image URL is passed as part of the user prompt, enabling the model to process both textual queries and visual information simultaneously. This capability is especially useful in applications like:\n",
    "\n",
    "- E-commerce product recognition\n",
    "- Medical image analysis\n",
    "- Social media content understanding\n",
    "\n",
    "Langfuse's tracing capabilities extend to these multi-modal interactions, providing visibility into how the model processes and responds to image inputs, which is crucial for debugging and improving these complex systems.\n",
    "\n",
    "In this use case, we will pass images as part of the user prompt and the model will process both the text and the image and langfuse will trace the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Multi-Modal Image Example\")\n",
    "def vision_api(\n",
    "    query: str,\n",
    "    image_url: str,\n",
    ") -> Optional[str]:\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"vision-session\",\n",
    "        tags=[\"lab1\", \"vision-example\"],\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI trained to describe and interpret images.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": simple_chat(\n",
    "            model_config=MODEL_CONFIG[\"nova_pro\"], messages=messages\n",
    "        ),\n",
    "        \"statusCode\": 200,\n",
    "    }\n",
    "\n",
    "\n",
    "# image source: https://www.aboutamazon.com/news/aws/aws-reinvent-2024-keynote-live-news-updates\n",
    "print(\n",
    "    vision_api(\n",
    "        query=\"What is happening in this image?\",\n",
    "        image_url=\"https://amazon-blogs-brightspot.s3.amazonaws.com/df/82/368cb270402e9739f04905ea9b19/swami-bedrock.jpeg\",\n",
    "    )\n",
    ")\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse also supports tracing with image input, this is very useful for a multi-modal use case in which the model can take image as input.\n",
    "\n",
    "![langfuse-traces-use-case-4](./images/langfuse-trace-use-case-4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Use with Langfuse Tracing\n",
    "Tool use enables AI models to interact with external functions and APIs, extending their capabilities beyond pure text generation. This is particularly useful for:\n",
    "- Accessing real-time data (e.g., weather, stock prices)\n",
    "- Performing complex calculations\n",
    "- Integrating with external systems\n",
    "- Extracting structured data from unstructured sources (e.g. text, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 1\n",
    "\n",
    "The example below demonstrates a weather information tool implementation. When a user asks about weather conditions, the model will:\n",
    "\n",
    "1. Recognize the need for weather data\n",
    "2. Extract location/unit parameters through structured tool definition\n",
    "3. Return a formatted response using our `get_current_weather` tool\n",
    "\n",
    "Expected result: The model should identify San Francisco as the location and celsius as the preferred unit, returning a structured tool response while maintaining full trace visibility in Langfuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [{'index': 0, 'id': 'tooluse_R6puKDXDR9KbpAoa1fd9ew', 'type': 'function', 'function': {'name': 'get_current_weather', 'arguments': '{\"unit\": \"celsius\", \"location\": \"San Francisco, CA\"}'}}], 'statusCode': 200}\n"
     ]
    }
   ],
   "source": [
    "@observe(name=\"Tool Use Example\")\n",
    "def tool_use_api(query: str) -> list:\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"tool-use-session\",\n",
    "        tags=[\"lab1\", \"tool-use\"],\n",
    "    )\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": query}]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                    },\n",
    "                    \"required\": [\"location\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": converse_tool_use(\n",
    "            messages, tools, tool_choice=\"auto\", **MODEL_CONFIG[\"nova_pro\"]\n",
    "        ),\n",
    "        \"statusCode\": 200,\n",
    "    }\n",
    "\n",
    "\n",
    "print(tool_use_api(query=\"What's the weather like in San Francisco?, in celsius?\"))\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![langfuse-traces-tool-use](./images/langfuse-trace-tool-use.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case 2\n",
    "The example below demonstrates a multi-modal document transcription tool implementation. When a user asks to transcribe a document, the model will:\n",
    "\n",
    "1. Recognize the schema for invoice transcription\n",
    "2. Extract structured data from images through structured tool definition\n",
    "3. Apply dependentSchemas to provide additional classification and reasoning for the extraction\n",
    "\n",
    "Expected result: The model should extract all the metadata and line items from the invoice and output the structured data in JSON format with classification and reasoning for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "<instructions>\n",
    "  - Ensure to escape quotes in the JSON response\n",
    "  - Return \"\" for missing field values\n",
    "  - Apply dependentSchemas to all <document/> fields\n",
    "</instructions>\n",
    "\n",
    "<document>\n",
    "{\n",
    "    \"$schema\": \"https://json-schema.org/draft/2020-12/schema\",\n",
    "    \"$id\": \"/schemas/document\",\n",
    "    \"type\": \"object\",\n",
    "    \"description\": \"A document with the fields to transcribe\",\n",
    "    \"properties\": {\n",
    "        \"doc_type\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Type of Document: Receipt\" },\n",
    "        \"receipt_number\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"The receipt number or other identifier number\" },\n",
    "        \"doc_amount_total\": { \"properties\":{\"value\":{\"type\":\"number\"}}, \"description\": \"The total receipt amount\" },\n",
    "        \"currency\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"AUD/USD/CAD\" },\n",
    "        \"vendor_business_number\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Vendor's business identification number e.g. ABN\" },\n",
    "        \"vendor_name\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Business name issueing the receipt\" },\n",
    "        \"vendor_address\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Vendor's site address\" },\n",
    "        \"vendor_phone\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"Vendor's phone number\" },\n",
    "        \"payment_method\": { \"properties\":{\"value\":{\"type\":\"string\"}}, \"description\": \"The payment type, e.g. EFTPOS, Card\" },\n",
    "        \"date_issued\": { \"properties\":{\"value\":{\"format\": \"YYYY-MM-DDThh:mm:ss\"}}, \"description\": \"Date document was issued\"},\n",
    "        \"line_items_amount_total\": { \"properties\":{\"value\":{\"type\":\"number\"}}, \"description\": \"Calculated sum of line item's line_amount fields\" }\n",
    "    },\n",
    "    \"dependentSchemas\": {\n",
    "        \"value\": {\n",
    "            \"properties\": {\n",
    "                \"inference\": { \"type\": \"integer\", \"description\": \"0=EXPLICIT|1=DERIVED|2=MISSING|3=OTHER\" },\n",
    "                \"source\": { \"type\": \"string\", \"description\": \"Source locations in the document for explicit and derived fields\" }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "<document/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@observe(name=\"Vision Tool Use Example\")\n",
    "def vision_tool_use_api(\n",
    "    query: str,\n",
    "    image_url: str,\n",
    ") -> list:\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"tool-use-session\",\n",
    "        tags=[\"lab1\", \"tool-use\"],\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt,\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    tools = [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"transcribe_documents\",\n",
    "                \"description\": \"Extract all <document/> fields with the highest accuracy following <instructions/>\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"documents\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\"$ref\": \"/schemas/document\"},\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"documents\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"response\": converse_tool_use(\n",
    "            messages, tools, tool_choice=\"auto\", **MODEL_CONFIG[\"nova_pro\"]\n",
    "        ),\n",
    "        \"statusCode\": 200,\n",
    "    }\n",
    "\n",
    "\n",
    "# image source: https://aws.amazon.com/blogs/machine-learning/announcing-expanded-support-for-extracting-data-from-invoices-and-receipts-using-amazon-textract/\n",
    "print(\n",
    "    vision_tool_use_api(\n",
    "        query=\"Transcribe the invoice. Make sure to apply dependentSchemas to all <document/> fields\",\n",
    "        image_url=\"https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2021/07/22/ml3911-img17.jpg\",\n",
    "    )\n",
    ")\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"./images/langfuse-trace-tool-use-vision.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Management\n",
    "### What is prompt management?\n",
    "\n",
    "Prompt management is a systematic approach to storing, versioning and retrieving prompts in LLM applications. Key aspects of prompt management include version control, decoupling prompts from code, monitoring, logging and optimizing prompts as well as integrating prompts with the rest of your application and tool stack.\n",
    "\n",
    "Use Langfuse to effectively **manage** and **version** your prompts. Langfuse prompt management is a Prompt **CMS** (Content Management System).\n",
    "\n",
    "\n",
    "### Why use prompt management?\n",
    "\n",
    "Typical benefits of using a CMS apply here:\n",
    "\n",
    "- Decoupling: deploy new prompts without redeploying your application.\n",
    "- Non-technical users can create and update prompts via Langfuse Console.\n",
    "- Quickly rollback to a previous version of a prompt.\n",
    "- Compare different prompt versions side-by-side.\n",
    "\n",
    "Platform benefits:\n",
    "\n",
    "- Track performance of prompt versions in Langfuse Tracing.\n",
    "- Performance benefits compared to other implementations:\n",
    "\n",
    "-  No latency impact after first use of a prompt due to client-side caching and asynchronous cache refreshing.\n",
    "-  Support for text and chat prompts.\n",
    "-  Edit/manage via UI, SDKs, or API.\n",
    "\n",
    "\n",
    "There are several ways you can create prompts in Langfuse:\n",
    "\n",
    "-  Langfuse Console\n",
    "-  Langfuse SDK\n",
    "-  Langfuse API\n",
    "\n",
    "In this workshop, we will be using Langfuse Python low-level SDK to create prompts by reusing the prompt exampels from the Modul1 - Prompt Engineering with Amazon Bedrock and Nova Model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Langfuse client\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# Create a chat prompt without COT\n",
    "langfuse.create_prompt(\n",
    "    name=\"software-development-project-management-without-COT\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"You are a project manager for a small software development team tasked with launching a new app feature. You want to streamline the development process and ensure timely delivery.\",\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"dev\"],\n",
    "    config={\n",
    "        \"model\": MODEL_CONFIG[\"nova_pro\"][\"model_id\"],\n",
    "        \"maxTokens\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"maxTokens\"],\n",
    "        \"temperature\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"temperature\"],\n",
    "    },  # for Dev and experiment phase\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat prompt with COT\n",
    "langfuse.create_prompt(\n",
    "    name=\"software-development-project-management-with-COT\",\n",
    "    type=\"chat\",\n",
    "    prompt=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"You are a project manager for a small software development team tasked with launching a new app feature. You want to streamline the development process and ensure timely delivery. Please follow these steps:\\n\n",
    "       {{step1}}\\n\n",
    "       \\n\n",
    "       {{step2}}\\n\n",
    "       \\n\n",
    "       {{step3}}\\n\n",
    "       \\n\n",
    "       {{step4}}\\n\"\"\",\n",
    "        }\n",
    "    ],\n",
    "    labels=[\"dev\"],\n",
    "    config={\n",
    "        \"model\": MODEL_CONFIG[\"nova_pro\"][\"model_id\"],\n",
    "        \"maxTokens\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"maxTokens\"],\n",
    "        \"temperature\": MODEL_CONFIG[\"nova_pro\"][\"inferenceConfig\"][\"temperature\"],\n",
    "    },  # for Dev and experiment phase\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the two langfuse prompts are created successfully.\n",
    "\n",
    "![langfuse-traces-prompt-management](./images/langfuse-prompt-management.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, fetch both prompts and fill in the values for the variables and call the prompts\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# Get current latest version of a prompt\n",
    "sdpm_with_cot_prompt = langfuse.get_prompt(\n",
    "    \"software-development-project-management-with-COT\", type=\"chat\", label=\"dev\"\n",
    ")\n",
    "# Insert variables into prompt template\n",
    "sdpm_with_cot_prompt_compiled = sdpm_with_cot_prompt.compile(\n",
    "    step1=\"Define Requirements\",\n",
    "    step2=\"Breakdown into Tasks\",\n",
    "    step3=\"Set Deadlines\",\n",
    "    step4=\"Monitor Progress and Optimize\",\n",
    ")\n",
    "\n",
    "sdpm_without_cot_prompt = langfuse.get_prompt(\n",
    "    \"software-development-project-management-without-COT\", type=\"chat\", label=\"dev\"\n",
    ")\n",
    "sdpm_without_cot_prompt_compiled = sdpm_without_cot_prompt.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdpm_with_cot_prompt_compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can add the prompt object to the generation call in the SDKs to link the generation in Langfuse Tracing to the prompt version. This linkage enables tracking of metrics by prompt version and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converesation according to AWS spec including prompting + history\n",
    "@observe()\n",
    "def main():\n",
    "    langfuse_context.update_current_trace(\n",
    "        name=\"prompt-management-trace\",\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"link-prompt-session\",\n",
    "        tags=[\"lab1\"],\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": sdpm_with_cot_prompt_compiled[0][\"role\"],\n",
    "            \"content\": sdpm_with_cot_prompt_compiled[0][\"content\"],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    simple_chat(\n",
    "        model_config=MODEL_CONFIG[\"nova_pro\"],\n",
    "        messages=messages,\n",
    "        prompt=sdpm_with_cot_prompt,\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": sdpm_without_cot_prompt_compiled[0][\"role\"],\n",
    "            \"content\": sdpm_without_cot_prompt_compiled[0][\"content\"],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    simple_chat(\n",
    "        model_config=MODEL_CONFIG[\"nova_pro\"],\n",
    "        messages=messages,\n",
    "        prompt=sdpm_without_cot_prompt,\n",
    "    )\n",
    "\n",
    "\n",
    "main()\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the trace is linked to the prompt version and the prompt name. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![langfuse-traces-prompt-management](./images/langfuse-link-prompt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab1 Summary:\n",
    "In Lab1, we explored the basics of integrating Langfuse with AWS to manage prompt traces effectively.\n",
    "We demonstrated how to update traces, link prompts to user sessions, and visualize these linkages with a practical example.\n",
    "\n",
    "As we conclude this lab, take a moment to reflect on the foundational skills you've gained.\n",
    "Now, if you are at an AWS event, you can return to the workshop studio for additional instructions before moving into the next lab, where we will dive deeper into RAG related tracing and evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaiops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
